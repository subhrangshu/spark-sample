{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.43.14:4040\n",
       "SparkContext available as 'sc' (version = 3.0.0-preview2, master = local[*], app id = local-1609167153569)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "<console>",
     "evalue": "24: error: object datastax is not a member of package com",
     "output_type": "error",
     "traceback": [
      "<console>:24: error: object datastax is not a member of package com",
      "       import com.datastax.spark.connector._",
      "                  ^",
      ""
     ]
    }
   ],
   "source": [
    "import com.datastax.spark.connector._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "2: error: Invalid literal number",
     "output_type": "error",
     "traceback": [
      "<console>:2: error: Invalid literal number",
      "       require: /mnt/1F8376FA6D76E846/IdeaProjects/Tests/SparkTest/cassandraconnector.jar",
      "                     ^",
      "<console>:2: error: Invalid literal number",
      "       require: /mnt/1F8376FA6D76E846/IdeaProjects/Tests/SparkTest/cassandraconnector.jar",
      "                       ^",
      ""
     ]
    }
   ],
   "source": [
    "require: /mnt/1F8376FA6D76E846/IdeaProjects/Tests/SparkTest/cassandraconnector.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " build.sbt\t\t  project\t\t\t\t     src\r\n",
      " cassandraconnector.jar   Python.ipynb\t\t\t\t     target\r\n",
      " LICENSE\t\t  README.md\r\n",
      " nodes.txt\t\t 'Scala Notebook with Spylon Kernel.ipynb'\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textFile: org.apache.spark.sql.Dataset[String] = [value: string]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val textFile = spark.read.textFile(\"README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res13: org.apache.spark.sql.Dataset[String] = [value: string]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Long = 5\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: String = This is a test\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linesWithSpark: org.apache.spark.sql.Dataset[String] = [value: string]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val linesWithSpark = textFile.filter(line => line.contains(\"Spark\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.Dataset[String] = [value: string]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linesWithSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res23: Long = 4\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.filter(line => line.contains(\"test\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ljava.lang.String;@45bb4645\n",
      "[Ljava.lang.String;@db11167\n",
      "[Ljava.lang.String;@76e54cbb\n",
      "[Ljava.lang.String;@4949e2cb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data: org.apache.spark.sql.Dataset[Array[String]] = [value: array<string>]\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = textFile.map(line => {\n",
    "    line.size\n",
    "    line.split(\" \")}\n",
    "    )\n",
    "data.take(4).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}